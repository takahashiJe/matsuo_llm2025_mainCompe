# HFリポジトリにアダプタ系ファイルが残っていたことで発生した不具合

## 何が起きたか（要約）
マージ済みモデルを使って推論するはずが、**ベースモデルが「アダプタ付き扱い」になってしまい**、
LoRAのマージ処理が失敗した。

## 症状
実行時に以下のような警告とエラーが出る。

- `Already found a peft_config attribute in the model`
- `UnboundLocalError: cannot access local variable 'active_adapters'`

## 本当の原因
**Hugging Face の「マージ済みモデル用リポジトリ」に、過去のアダプタ系ファイルが残っていた**。

同じリポジトリ内に以下のようなファイルがあると、PEFT/Transformers は
「これはアダプタモデルだ」と判断しやすい。

- `adapter_config.json`
- `adapter_model.safetensors` / `adapter_model.bin`
- `adapter_*` 系ファイル

結果として、**マージ済みモデルをベースに読み込むはずが、PEFTモデルとして扱われる**。
その状態で新しいアダプタをマージすると `save_pretrained()` が破綻する。

## ここが分かりにくい仕様（今回の盲点）
- **HFは「リポジトリ単位」でファイルを残す**  
  同じリポジトリにアップロードし直しても、不要ファイルは自動で消えない。
- **`--merged` でアップロードしても「過去のアダプタファイル」は残り得る**  
  その結果、見た目はマージ済みに見えてもPEFT扱いになることがある。
- **PEFT/Transformersは「ファイルの存在」でアダプタ判定しやすい**  
  `adapter_config.json` が残っているだけで、ベース側に `peft_config` が付く。
- **キャッシュ削除だけでは解決しないことがある**  
  問題はローカルではなく「HFリポジトリの残留ファイル」だったため。

## 再現条件（一般化）
以下が揃うと同種の不具合が起きやすい。

- マージ済みモデル用のHFリポジトリに、アダプタ系ファイルが混在
- そのリポジトリを「ベースモデル」として読み込む
- さらに別のアダプタを `merge_and_unload()` して保存する

## 解決方法（確実）
**HF上のマージ済みモデルリポジトリからアダプタ系ファイルを完全に除去**する。

やり方はどちらでもよい。

1. リポジトリを削除して作り直す（最も確実）
2. `adapter_*` をHF上から手動削除する

その後、**マージ済みモデルのみをアップロードし直せば解決**する。

## 予防策（今後のベストプラクティス）
- マージ済みモデル用のリポジトリとアダプタ用のリポジトリを混在させない
- `upload_hf.py --merged` 実行時に `adapter_config.json` が混入していないことを必ず検証する
- アップロード後にHF上のファイル一覧を確認して、不要ファイルが残っていないかチェックする
